{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"/home/nguyen/\"\n",
    "RAW_DATA = \"/data/labeled_tweets.txt\"\n",
    "PROCESSED_DATA = \"data/processed_tweets.csv\"\n",
    "GLOVE_6B_50D_PATH = WORK_DIR +\"Glove6B/glove.6B.50d.txt\"\n",
    "GLOVE_840B_300D_PATH = WORK_DIR+\"glove.840B.300d.txt\"\n",
    "ENCODING = \"utf-8\"\n",
    "CHARACTER_VOCAB = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:’\\\"/\\|_#$%&^*~‘+-=<>()[]{}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and split train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: (302925, 2)\n",
      "Data after removing NAN rows: (302453, 2)\n"
     ]
    }
   ],
   "source": [
    "# read data and split train, test\n",
    "data = pd.read_csv(WORK_DIR+PROCESSED_DATA)\n",
    "# data = pd.read_csv(\"../examples.csv\")\n",
    "print(\"data size: {}\".format(data.shape))\n",
    "data.dropna(subset=['tweets'], inplace=True)\n",
    "print(\"Data after removing NAN rows: {}\".format(data.shape))\n",
    "\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "labels = labelEncoder.fit_transform(data.labels.values)\n",
    "\n",
    "\n",
    "dataTrain, dataTest, labelTrain, labelTest = train_test_split(data.tweets.values, labels,\n",
    "                                                              test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         tweets\n",
      "labels                         \n",
      "Business                  35539\n",
      "Education                 12925\n",
      "Entertainment             22484\n",
      "Health                    28798\n",
      "Law and Crime             16105\n",
      "Politics                  45089\n",
      "Religion                  11310\n",
      "Science and Technology    32256\n",
      "Sports                    43503\n",
      "Travel                    38394\n",
      "Weather and Environment   16050\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('labels').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained glove embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read glove vectors\n",
    "glove_small = {}\n",
    "\n",
    "all_words = set(w for words in dataTrain for w in words)\n",
    "with open(GLOVE_6B_50D_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode(ENCODING)\n",
    "        if (word in all_words):\n",
    "            nums=np.array(parts[1:], dtype=np.float32)\n",
    "            glove_small[word] = nums\n",
    "\n",
    "            \n",
    "glove_big = {}\n",
    "with open(GLOVE_840B_300D_PATH, \"rb\") as infile:\n",
    "    for line in infile:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode(ENCODING)\n",
    "        if word in all_words:\n",
    "            nums=np.array(parts[1:], dtype=np.float32)\n",
    "            glove_big[word] = nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn word embedding from scratch using only train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec embendding trained from scratch\n",
    "model = Word2Vec(dataTrain, size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, list(model.wv.vectors))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways to form tweet vector by combining word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim=len(word2vec[next(iter(word2vec))])\n",
    "            \n",
    "    def fit(self, X):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "##> each input is represented as a mean of embedding*tfidf if individual words\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim=len(word2vec[next(iter(word2vec))])\n",
    "       \n",
    "        \n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(name, model, vectorizer):\n",
    "    vectorizer.fit(dataTrain)\n",
    "    features_train = vectorizer.transform(dataTrain)\n",
    "    features_test = vectorizer.transform(dataTest)\n",
    "    print(\"Training features: {}\".format(features_train.shape))\n",
    "    # print(vectorizer.get_feature_names())\n",
    "    print(\"Training......................\")\n",
    "    \n",
    "    model.fit(features_train, labelTrain)\n",
    "    print(\"Predicting....................\")\n",
    "    predTest = model.predict(features_test)\n",
    "    f1_test = f1_score(predTest, labelTest, average = 'micro')\n",
    "    f1_train = f1_score(model.predict(features_train), labelTrain, average = 'micro')\n",
    "    print(\"Model: {} F1 Train: {}\\n\".format(name, f1_train))\n",
    "    print(\"Model: {} F1 Test: {}\\n\".format(name, f1_test))\n",
    "    print(classification_report(predTest, labelTest))\n",
    "#     f1_scores.append(f1)\n",
    "    return f1_train, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 101030)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: svc_tfidf F1 Train: 0.7757705755449202\n",
      "\n",
      "Model: svc_tfidf F1 Test: 0.7576168355623151\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.66      0.60      5934\n",
      "           1       0.68      0.79      0.73      2219\n",
      "           2       0.68      0.80      0.73      3796\n",
      "           3       0.78      0.72      0.75      6248\n",
      "           4       0.61      0.83      0.70      2362\n",
      "           5       0.87      0.77      0.82     10195\n",
      "           6       0.58      0.92      0.71      1424\n",
      "           7       0.61      0.68      0.64      5748\n",
      "           8       0.94      0.79      0.86     10266\n",
      "           9       0.89      0.73      0.80      9328\n",
      "          10       0.82      0.88      0.85      2971\n",
      "\n",
      "    accuracy                           0.76     60491\n",
      "   macro avg       0.73      0.78      0.74     60491\n",
      "weighted avg       0.78      0.76      0.76     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svc tfidf\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "model_name = \"svc_tfidf\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "svc_tfidf = LinearSVC(multi_class='ovr', C = 0.01, random_state=42)\n",
    "f1_train, f1_test = run_model(model_name, svc_tfidf, vectorizer)\n",
    "f1_scores_train.append([model_name, f1_train])\n",
    "f1_scores_test.append([model_name, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer......................\n",
      "Training features: (241962, 100)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: w2v_meanEmbedding F1 Train: 0.9904075846620544\n",
      "\n",
      "Model: w2v_meanEmbedding F1 Test: 0.41754971813988856\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.45      0.37      5006\n",
      "           1       0.35      0.82      0.49      1108\n",
      "           2       0.26      0.72      0.38      1641\n",
      "           3       0.37      0.61      0.46      3475\n",
      "           4       0.31      0.64      0.42      1559\n",
      "           5       0.65      0.36      0.46     16492\n",
      "           6       0.24      0.94      0.38       580\n",
      "           7       0.27      0.41      0.32      4199\n",
      "           8       0.61      0.33      0.42     16095\n",
      "           9       0.46      0.41      0.43      8666\n",
      "          10       0.26      0.51      0.35      1670\n",
      "\n",
      "    accuracy                           0.42     60491\n",
      "   macro avg       0.37      0.56      0.41     60491\n",
      "weighted avg       0.50      0.42      0.42     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean word2vec\n",
    "print(\"Vectorizer......................\")\n",
    "model_name = 'w2v_meanEmbedding'\n",
    "vectorizer = MeanEmbeddingVectorizer(w2v)\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "f1_train, f1_test = run_model(model_name, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_train.append([model_name, f1_train])\n",
    "f1_scores_test.append([model_name, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['svc_tfidf', 0.7757705755449202], ['w2v_meanEmbedding', 0.9904075846620544]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 100)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: w2v_tfidfEmbedding F1 Train: 0.9904075846620544\n",
      "\n",
      "Model: w2v_tfidfEmbedding F1 Test: 0.4247739333123936\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.51      0.38      4297\n",
      "           1       0.35      0.85      0.49      1051\n",
      "           2       0.26      0.83      0.40      1425\n",
      "           3       0.36      0.65      0.46      3231\n",
      "           4       0.29      0.71      0.42      1333\n",
      "           5       0.67      0.36      0.47     16834\n",
      "           6       0.24      0.96      0.38       555\n",
      "           7       0.27      0.44      0.33      3856\n",
      "           8       0.63      0.33      0.43     16714\n",
      "           9       0.49      0.40      0.44      9352\n",
      "          10       0.29      0.50      0.37      1843\n",
      "\n",
      "    accuracy                           0.42     60491\n",
      "   macro avg       0.38      0.59      0.42     60491\n",
      "weighted avg       0.52      0.42      0.43     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tfidf weighted word2vec\n",
    "model_name = \"w2v_tfidfEmbedding\"\n",
    "vectorizer = TfidfEmbeddingVectorizer(w2v)\n",
    "model = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "f1_train, f1_test = run_model(model_name, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_train.append([model_name, f1_train])\n",
    "f1_scores_test.append([model_name, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 50)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: global_small F1 Train: 0.9903951860209455\n",
      "\n",
      "Model: global_small F1 Test: 0.4055809955199947\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.50      0.38      4384\n",
      "           1       0.32      0.91      0.48       910\n",
      "           2       0.26      0.77      0.38      1496\n",
      "           3       0.35      0.67      0.46      2993\n",
      "           4       0.22      0.74      0.34       953\n",
      "           5       0.65      0.34      0.44     17539\n",
      "           6       0.24      0.96      0.38       558\n",
      "           7       0.25      0.44      0.32      3713\n",
      "           8       0.60      0.30      0.40     17378\n",
      "           9       0.48      0.39      0.43      9426\n",
      "          10       0.20      0.57      0.30      1141\n",
      "\n",
      "    accuracy                           0.41     60491\n",
      "   macro avg       0.35      0.60      0.39     60491\n",
      "weighted avg       0.51      0.41      0.41     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pretrained glove_small embedding\n",
    "model_name = \"global_small\"\n",
    "vectorizer = MeanEmbeddingVectorizer(glove_small)\n",
    "model = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "f1_train, f1_test = run_model(model_name, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_train.append([model_name, f1_train])\n",
    "f1_scores_test.append([model_name, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 50)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: glove_small_tfidf F1 Train: 0.9904034517816848\n",
      "\n",
      "Model: glove_small_tfidf F1 Test: 0.4148385710270949\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.51      0.38      4256\n",
      "           1       0.32      0.93      0.48       899\n",
      "           2       0.26      0.78      0.39      1523\n",
      "           3       0.35      0.68      0.47      2992\n",
      "           4       0.22      0.78      0.35       914\n",
      "           5       0.67      0.34      0.46     17564\n",
      "           6       0.23      0.96      0.38       552\n",
      "           7       0.25      0.45      0.33      3635\n",
      "           8       0.62      0.31      0.41     17249\n",
      "           9       0.49      0.40      0.44      9603\n",
      "          10       0.24      0.59      0.34      1304\n",
      "\n",
      "    accuracy                           0.41     60491\n",
      "   macro avg       0.36      0.61      0.40     60491\n",
      "weighted avg       0.53      0.41      0.42     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pretrained glove_small weighted embedding\n",
    "model_name = \"glove_small_tfidf\"\n",
    "vectorizer = TfidfEmbeddingVectorizer(glove_small)\n",
    "model = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "f1 = run_model(model_name, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_train.append([model_name, f1_train])\n",
    "f1_scores_test.append([model_name, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 300)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: glove_big F1 Train: 0.9904034517816848\n",
      "\n",
      "Model: glove_big F1 Test: 0.4283116496668926\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.51      0.39      4319\n",
      "           1       0.36      0.86      0.50      1078\n",
      "           2       0.27      0.77      0.40      1543\n",
      "           3       0.37      0.63      0.47      3374\n",
      "           4       0.26      0.76      0.39      1117\n",
      "           5       0.68      0.36      0.47     16919\n",
      "           6       0.24      0.96      0.38       559\n",
      "           7       0.27      0.45      0.33      3822\n",
      "           8       0.62      0.32      0.43     16716\n",
      "           9       0.51      0.41      0.46      9435\n",
      "          10       0.28      0.56      0.37      1609\n",
      "\n",
      "    accuracy                           0.43     60491\n",
      "   macro avg       0.38      0.60      0.42     60491\n",
      "weighted avg       0.53      0.43      0.44     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"glove_big\"\n",
    "vectorizer = MeanEmbeddingVectorizer(glove_big)\n",
    "model = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "f1_train, f1_test = run_model(model_name, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_train.append([model_name, f1_train])\n",
    "f1_scores_test.append([model_name, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 300)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: glove_big_tfidf F1 Train: 0.9904034517816848\n",
      "\n",
      "Model: glove_big_tfidf F1 Test: 0.4339488518953233\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.51      0.39      4341\n",
      "           1       0.35      0.86      0.49      1044\n",
      "           2       0.27      0.82      0.41      1501\n",
      "           3       0.37      0.65      0.47      3327\n",
      "           4       0.26      0.79      0.39      1075\n",
      "           5       0.68      0.37      0.48     16675\n",
      "           6       0.24      0.97      0.38       557\n",
      "           7       0.27      0.45      0.34      3873\n",
      "           8       0.64      0.33      0.44     16729\n",
      "           9       0.52      0.42      0.46      9510\n",
      "          10       0.30      0.53      0.39      1859\n",
      "\n",
      "    accuracy                           0.43     60491\n",
      "   macro avg       0.38      0.61      0.42     60491\n",
      "weighted avg       0.53      0.43      0.44     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"glove_big_tfidf\"\n",
    "vectorizer = TfidfEmbeddingVectorizer(glove_big)\n",
    "model = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "f1 = run_model(model_name, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_train.append([model_name, f1_train])\n",
    "f1_scores_test.append([model_name, f1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               models  F1_train   F1_test\n",
      "0           svc_tfidf  0.775771  0.757617\n",
      "1   w2v_meanEmbedding  0.990408  0.417550\n",
      "2  w2v_tfidfEmbedding  0.990408  0.424774\n",
      "3        global_small  0.990395  0.405581\n",
      "4   glove_small_tfidf  0.990395  0.405581\n",
      "5           glove_big  0.990403  0.428312\n",
      "6     glove_big_tfidf  0.990403  0.428312\n",
      "7     glove_big_tfidf  0.990403  0.428312\n",
      "8     glove_big_tfidf  0.990403  0.428312\n",
      "9     glove_big_tfidf  0.990403  0.428312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), <a list of 10 Text xticklabel objects>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plottedData = pd.DataFrame(f1_scores_train, columns = ['models', 'F1_train'])\n",
    "plottedData = plottedData.merge(pd.DataFrame(f1_scores_test, columns =['models', 'F1_test']), how = 'left', on='models')\n",
    "print(plottedData)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (14,6)\n",
    "plottedData.plot(x = 'models', y = ['F1_train', 'F1_test'], kind = 'bar')\n",
    "plt.xticks(rotation = '30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on a simpler model: Reduce number of estimators\n",
    "- Result on test set gets reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 300)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: glove_big_tfidf F1 Train: 0.9904034517816848\n",
      "\n",
      "Model: glove_big_tfidf F1 Test: 0.3696417648906449\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.30      0.33      8943\n",
      "           1       0.36      0.58      0.45      1630\n",
      "           2       0.31      0.36      0.33      3854\n",
      "           3       0.39      0.41      0.40      5397\n",
      "           4       0.26      0.40      0.32      2096\n",
      "           5       0.53      0.36      0.43     13104\n",
      "           6       0.25      0.60      0.35       921\n",
      "           7       0.27      0.33      0.30      5317\n",
      "           8       0.41      0.33      0.36     10795\n",
      "           9       0.38      0.43      0.41      6791\n",
      "          10       0.22      0.43      0.29      1643\n",
      "\n",
      "    accuracy                           0.37     60491\n",
      "   macro avg       0.34      0.41      0.36     60491\n",
      "weighted avg       0.39      0.37      0.37     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reduce the number of estimators\n",
    "model_name = \"glove_big_tfidf\"\n",
    "vectorizer = TfidfEmbeddingVectorizer(glove_big)\n",
    "model = ExtraTreesClassifier(n_estimators=15, random_state=42)\n",
    "f1 = run_model(model_name, model, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec embedding trained from scratch on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (241962, 100)\n",
      "Training......................\n",
      "Predicting....................\n",
      "Model: w2v_allData F1 Train: 0.9904075846620544\n",
      "\n",
      "Model: w2v_allData F1 Test: 0.42715445272850505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.51      0.38      4301\n",
      "           1       0.34      0.87      0.49      1008\n",
      "           2       0.26      0.81      0.39      1437\n",
      "           3       0.36      0.67      0.47      3129\n",
      "           4       0.29      0.72      0.42      1318\n",
      "           5       0.66      0.35      0.46     16921\n",
      "           6       0.23      0.96      0.38       548\n",
      "           7       0.28      0.43      0.34      4149\n",
      "           8       0.65      0.33      0.44     16975\n",
      "           9       0.49      0.41      0.45      9169\n",
      "          10       0.27      0.56      0.36      1536\n",
      "\n",
      "    accuracy                           0.43     60491\n",
      "   macro avg       0.38      0.60      0.42     60491\n",
      "weighted avg       0.53      0.43      0.43     60491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(data.tweets.values, size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, list(model.wv.vectors))}\n",
    "\n",
    "model_name = \"w2v_allData\"\n",
    "vectorizer = MeanEmbeddingVectorizer(w2v)\n",
    "model = ExtraTreesClassifier(n_estimators=200, random_state=42)\n",
    "f1_train, f1_test = run_model(model_name, model, vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character level tweet embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"/home/nguyen/\"\n",
    "RAW_DATA = \"/data/labeled_tweets.txt\"\n",
    "PROCESSED_DATA = \"data/processed_tweets.csv\"\n",
    "GLOVE_6B_50D_PATH = WORK_DIR +\"Glove6B/glove.6B.50d.txt\"\n",
    "GLOVE_840B_300D_PATH = WORK_DIR+\"glove.840B.300d.txt\"\n",
    "ENCODING = \"utf-8\"\n",
    "CHARACTER_VOCAB = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:’\\\"/\\|_#$%&^*~‘+-=<>()[]{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter settings\n",
    "max_len = 140\n",
    "vocab_size = 75\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "hidden_size = 50\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: (302925, 2)\n",
      "Data after removing NAN rows: (302453, 2)\n"
     ]
    }
   ],
   "source": [
    "# read data and split train, test\n",
    "data = pd.read_csv(WORK_DIR+PROCESSED_DATA)\n",
    "# data = pd.read_csv(\"../examples.csv\")\n",
    "print(\"data size: {}\".format(data.shape))\n",
    "data.dropna(subset=['tweets'], inplace=True)\n",
    "print(\"Data after removing NAN rows: {}\".format(data.shape))\n",
    "\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "labels = labelEncoder.fit_transform(data.labels.values)\n",
    "\n",
    "\n",
    "dataTrain, dataTest, labelTrain, labelTest = train_test_split(data.tweets.values, labels,\n",
    "                                                              test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert data to index vectors\n",
    "# int2char = dict(enumerate(CHARACTER_VOCAB))\n",
    "# char2int = {char: index+1 for index, char in int2char.items()}\n",
    "\n",
    "\n",
    "# def charToIndex(data, max_len):\n",
    "#     encoded = np.zeros((data.shape[0], max_len), dtype=np.int64)\n",
    "    \n",
    "#     lineCount = 0\n",
    "#     for line in data:\n",
    "#         charCount=0\n",
    "#         for index_char, char in enumerate(line[::-1]):\n",
    "#             charCount+=1\n",
    "    \n",
    "            \n",
    "#             if charCount> max_len:\n",
    "#                 break\n",
    "#             if char in char2int:\n",
    "#                 encoded[lineCount][index_char] = char2int[char]\n",
    "#         lineCount +=1\n",
    "#     return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one-hot vector\n",
    "# def oneHotVector(data, vocab_size):\n",
    "   \n",
    "#     one_hot = torch.zeros((np.multiply(*data.shape), vocab_size), dtype=torch.int32)\n",
    "#     # Fill the appropriate elements with ones\n",
    "#     one_hot[np.arange(one_hot.shape[0]), data.flatten()] = 1.\n",
    "    \n",
    "#     # Finally reshape it to get back to the original array\n",
    "#     one_hot = one_hot.reshape((*data.shape, vocab_size))\n",
    "    \n",
    "#     return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test\n",
    "# x = np.array(['fdfd', 'sfe'])\n",
    "# encoded = charToIndex(x, 14)\n",
    "# print(encoded)\n",
    "# test_seq = np.array([[3, 5, 1], [4,3,2]])\n",
    "# print(test_seq)\n",
    "# one_hot = oneHotVector(encoded, 20)\n",
    "\n",
    "# print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# x_train = charToIndex(dataTrain, max_len)\n",
    "# x_test = charToIndex(dataTest, max_len)\n",
    "# y_train = torch.LongTensor(labelTrain)\n",
    "# y_test = torch.LongTensor(labelTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labelTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(Dataset):\n",
    "    def __init__(self, data, labels, alphabet, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.y = torch.LongTensor(labels)\n",
    "        self.data = data\n",
    "        self.label = labels\n",
    "        self.alphabet = alphabet\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.index(idx)\n",
    "        y = self.y[idx]\n",
    "        return X, y\n",
    "\n",
    "    def index(self, idx):\n",
    "        X = torch.zeros(self.max_len, dtype = torch.long)\n",
    "        sequence = self.data[idx]\n",
    "        i=0\n",
    "        for index_char, char in enumerate(sequence[::-1]):\n",
    "            i+=1\n",
    "            if i> self.max_len:\n",
    "                break\n",
    "            if self.char2Index(char)!=-1:\n",
    "                X[index_char] = self.char2Index(char)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def oneHotEncode(self, idx):\n",
    "        # X = (batch, 70, sequence_length)\n",
    "        X = torch.zeros(len(self.alphabet), self.max_len)\n",
    "       \n",
    "        sequence = self.data[idx]\n",
    "        \n",
    "        i=0\n",
    "        for index_char, char in enumerate(sequence[::-1]):\n",
    "            i+=1\n",
    "            if i> self.max_len:\n",
    "                break\n",
    "            if self.char2Index(char)!=-1:\n",
    "                X[self.char2Index(char)][index_char] = 1.0\n",
    "        return X\n",
    "\n",
    "    def char2Index(self, character):\n",
    "        return self.alphabet.find(character)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataReader(dataTrain, labelTrain, CHARACTER_VOCAB, max_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, num_workers=4, drop_last=False)\n",
    "\n",
    "test_dataset = DataReader(dataTest, labelTest, CHARACTER_VOCAB, max_len)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64*2, num_workers=4, drop_last=False)\n",
    "\n",
    "# for i_batch, sample_batched in enumerate(train_loader):\n",
    "#     if i_batch == 0:\n",
    "#         print(sample_batched[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(BiGRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional = False)\n",
    "        \n",
    "        \n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "#         print(input.shape)\n",
    "        batch_size = input.size(0)\n",
    "        embedded = self.embedding(input).view(input.size(1),batch_size,-1)\n",
    "#         print(embedded.shape)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "#         print(output.shape)\n",
    "        \n",
    "        output = self.out(output).view(batch_size, -1)\n",
    "#         print(output.shape)\n",
    "        return output, hidden\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layers' size:\n",
    "- input size:  \n",
    "    + torch.Size([64, 140]): batch_size, max_len\n",
    "- embedding size:\n",
    "    + torch.Size([140, 64, 50]): max_len, batch_size, embedding_size\n",
    "- GRU size:\n",
    "    + torch.Size([140, 64, 50]): max_len, batch_size, embedding_size\n",
    "- Linear size: \n",
    "    + torch.Size([64, 1540]): batch_size, flatten_GRU\n",
    "- Softmax:\n",
    "    + torch.Size([64, 1]): batch_size, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiGRUModel(vocab_size, hidden_size, len(set(labelTrain)))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  (241962,)\n",
      "Batch:  64\n",
      "#Number of iter per each epoch:  3780.65625\n",
      "Test size:  (60491,)\n",
      "#iters per epoch:  315.0572916666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size: \", dataTrain.shape)\n",
    "print(\"Batch: \", batch_size)\n",
    "print(\"#Number of iter per each epoch: \", (dataTrain.shape[0]/batch_size))\n",
    "\n",
    "print(\"Test size: \", dataTest.shape)\n",
    "print(\"#iters per epoch: \", (dataTest.shape[0]/(3*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiGRUModel(\n",
       "  (embedding): Embedding(75, 50)\n",
       "  (gru): GRU(50, 50)\n",
       "  (out): Linear(in_features=50, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--(Epoch, iter): [1,    50] loss: 6.448\n",
      "--(Epoch, iter): [1,   100] loss: 6.376\n",
      "--(Epoch, iter): [1,   150] loss: 6.342\n",
      "--(Epoch, iter): [1,   200] loss: 6.287\n",
      "--(Epoch, iter): [1,   250] loss: 6.280\n",
      "--(Epoch, iter): [1,   300] loss: 6.287\n",
      "--(Epoch, iter): [1,   350] loss: 6.231\n",
      "--(Epoch, iter): [1,   400] loss: 6.211\n",
      "--(Epoch, iter): [1,   450] loss: 6.223\n",
      "--(Epoch, iter): [1,   500] loss: 6.198\n",
      "--(Epoch, iter): [1,   550] loss: 6.192\n",
      "--(Epoch, iter): [1,   600] loss: 6.155\n",
      "--(Epoch, iter): [1,   650] loss: 6.176\n",
      "--(Epoch, iter): [1,   700] loss: 6.143\n",
      "--(Epoch, iter): [1,   750] loss: 6.195\n",
      "--(Epoch, iter): [1,   800] loss: 6.147\n",
      "--(Epoch, iter): [1,   850] loss: 6.173\n",
      "--(Epoch, iter): [1,   900] loss: 6.164\n",
      "--(Epoch, iter): [1,   950] loss: 6.139\n",
      "--(Epoch, iter): [1,  1000] loss: 6.154\n",
      "--(Epoch, iter): [1,  1050] loss: 6.139\n",
      "--(Epoch, iter): [1,  1100] loss: 6.117\n",
      "--(Epoch, iter): [1,  1150] loss: 6.104\n",
      "--(Epoch, iter): [1,  1200] loss: 6.165\n",
      "--(Epoch, iter): [1,  1250] loss: 6.106\n",
      "--(Epoch, iter): [1,  1300] loss: 6.127\n",
      "--(Epoch, iter): [1,  1350] loss: 6.083\n",
      "--(Epoch, iter): [1,  1400] loss: 6.133\n",
      "--(Epoch, iter): [1,  1450] loss: 6.142\n",
      "--(Epoch, iter): [1,  1500] loss: 6.098\n",
      "--(Epoch, iter): [1,  1550] loss: 6.076\n",
      "--(Epoch, iter): [1,  1600] loss: 6.085\n",
      "--(Epoch, iter): [1,  1650] loss: 6.109\n",
      "--(Epoch, iter): [1,  1700] loss: 6.042\n",
      "--(Epoch, iter): [1,  1750] loss: 6.072\n",
      "--(Epoch, iter): [1,  1800] loss: 6.088\n",
      "--(Epoch, iter): [1,  1850] loss: 6.110\n",
      "--(Epoch, iter): [1,  1900] loss: 6.115\n",
      "--(Epoch, iter): [1,  1950] loss: 6.105\n",
      "--(Epoch, iter): [1,  2000] loss: 6.077\n",
      "--(Epoch, iter): [1,  2050] loss: 6.111\n",
      "--(Epoch, iter): [1,  2100] loss: 6.116\n",
      "--(Epoch, iter): [1,  2150] loss: 6.066\n",
      "--(Epoch, iter): [1,  2200] loss: 6.096\n",
      "--(Epoch, iter): [1,  2250] loss: 6.085\n",
      "--(Epoch, iter): [1,  2300] loss: 6.064\n",
      "--(Epoch, iter): [1,  2350] loss: 6.071\n",
      "--(Epoch, iter): [1,  2400] loss: 6.080\n",
      "--(Epoch, iter): [1,  2450] loss: 6.046\n",
      "--(Epoch, iter): [1,  2500] loss: 6.033\n",
      "--(Epoch, iter): [1,  2550] loss: 6.028\n",
      "--(Epoch, iter): [1,  2600] loss: 6.037\n",
      "--(Epoch, iter): [1,  2650] loss: 6.059\n",
      "--(Epoch, iter): [1,  2700] loss: 6.049\n",
      "--(Epoch, iter): [1,  2750] loss: 6.077\n",
      "--(Epoch, iter): [1,  2800] loss: 6.078\n",
      "--(Epoch, iter): [1,  2850] loss: 6.029\n",
      "--(Epoch, iter): [1,  2900] loss: 6.042\n",
      "--(Epoch, iter): [1,  2950] loss: 6.042\n",
      "--(Epoch, iter): [1,  3000] loss: 6.071\n",
      "--(Epoch, iter): [1,  3050] loss: 6.061\n",
      "--(Epoch, iter): [1,  3100] loss: 6.062\n",
      "--(Epoch, iter): [1,  3150] loss: 6.000\n",
      "--(Epoch, iter): [1,  3200] loss: 6.032\n",
      "--(Epoch, iter): [1,  3250] loss: 6.032\n",
      "--(Epoch, iter): [1,  3300] loss: 6.046\n",
      "--(Epoch, iter): [1,  3350] loss: 6.031\n",
      "--(Epoch, iter): [1,  3400] loss: 6.015\n",
      "--(Epoch, iter): [1,  3450] loss: 6.014\n",
      "--(Epoch, iter): [1,  3500] loss: 6.014\n",
      "--(Epoch, iter): [1,  3550] loss: 6.003\n",
      "--(Epoch, iter): [1,  3600] loss: 6.046\n",
      "--(Epoch, iter): [1,  3650] loss: 6.026\n",
      "--(Epoch, iter): [1,  3700] loss: 6.008\n",
      "--(Epoch, iter): [1,  3750] loss: 6.040\n",
      "Epoch:  0 --- Loss:  tensor(5.7925) ---F1:  0.02270591085271318\n",
      "--(Epoch, iter): [2,    50] loss: 6.055\n",
      "--(Epoch, iter): [2,   100] loss: 5.969\n",
      "--(Epoch, iter): [2,   150] loss: 5.983\n",
      "--(Epoch, iter): [2,   200] loss: 5.951\n",
      "--(Epoch, iter): [2,   250] loss: 5.937\n",
      "--(Epoch, iter): [2,   300] loss: 5.944\n",
      "--(Epoch, iter): [2,   350] loss: 5.839\n",
      "--(Epoch, iter): [2,   400] loss: 5.792\n",
      "--(Epoch, iter): [2,   450] loss: 5.780\n",
      "--(Epoch, iter): [2,   500] loss: 5.736\n",
      "--(Epoch, iter): [2,   550] loss: 5.690\n",
      "--(Epoch, iter): [2,   600] loss: 5.640\n",
      "--(Epoch, iter): [2,   650] loss: 5.665\n",
      "--(Epoch, iter): [2,   700] loss: 5.580\n",
      "--(Epoch, iter): [2,   750] loss: 5.661\n",
      "--(Epoch, iter): [2,   800] loss: 5.586\n",
      "--(Epoch, iter): [2,   850] loss: 5.606\n",
      "--(Epoch, iter): [2,   900] loss: 5.624\n",
      "--(Epoch, iter): [2,   950] loss: 5.602\n",
      "--(Epoch, iter): [2,  1000] loss: 5.601\n",
      "--(Epoch, iter): [2,  1050] loss: 5.574\n",
      "--(Epoch, iter): [2,  1100] loss: 5.521\n",
      "--(Epoch, iter): [2,  1150] loss: 5.546\n",
      "--(Epoch, iter): [2,  1200] loss: 5.644\n",
      "--(Epoch, iter): [2,  1250] loss: 5.535\n",
      "--(Epoch, iter): [2,  1300] loss: 5.562\n",
      "--(Epoch, iter): [2,  1350] loss: 5.521\n",
      "--(Epoch, iter): [2,  1400] loss: 5.548\n",
      "--(Epoch, iter): [2,  1450] loss: 5.589\n",
      "--(Epoch, iter): [2,  1500] loss: 5.527\n",
      "--(Epoch, iter): [2,  1550] loss: 5.523\n",
      "--(Epoch, iter): [2,  1600] loss: 5.521\n",
      "--(Epoch, iter): [2,  1650] loss: 5.529\n",
      "--(Epoch, iter): [2,  1700] loss: 5.433\n",
      "--(Epoch, iter): [2,  1750] loss: 5.512\n",
      "--(Epoch, iter): [2,  1800] loss: 5.524\n",
      "--(Epoch, iter): [2,  1850] loss: 5.539\n",
      "--(Epoch, iter): [2,  1900] loss: 5.523\n",
      "--(Epoch, iter): [2,  1950] loss: 5.521\n",
      "--(Epoch, iter): [2,  2000] loss: 5.541\n",
      "--(Epoch, iter): [2,  2050] loss: 5.520\n",
      "--(Epoch, iter): [2,  2100] loss: 5.573\n",
      "--(Epoch, iter): [2,  2150] loss: 5.505\n",
      "--(Epoch, iter): [2,  2200] loss: 5.491\n",
      "--(Epoch, iter): [2,  2250] loss: 5.487\n",
      "--(Epoch, iter): [2,  2300] loss: 5.491\n",
      "--(Epoch, iter): [2,  2350] loss: 5.483\n",
      "--(Epoch, iter): [2,  2400] loss: 5.487\n",
      "--(Epoch, iter): [2,  2450] loss: 5.458\n",
      "--(Epoch, iter): [2,  2500] loss: 5.423\n",
      "--(Epoch, iter): [2,  2550] loss: 5.435\n",
      "--(Epoch, iter): [2,  2600] loss: 5.442\n",
      "--(Epoch, iter): [2,  2650] loss: 5.437\n",
      "--(Epoch, iter): [2,  2700] loss: 5.406\n",
      "--(Epoch, iter): [2,  2750] loss: 5.453\n",
      "--(Epoch, iter): [2,  2800] loss: 5.450\n",
      "--(Epoch, iter): [2,  2850] loss: 5.379\n",
      "--(Epoch, iter): [2,  2900] loss: 5.365\n",
      "--(Epoch, iter): [2,  2950] loss: 5.336\n",
      "--(Epoch, iter): [2,  3000] loss: 5.285\n",
      "--(Epoch, iter): [2,  3050] loss: 5.264\n",
      "--(Epoch, iter): [2,  3100] loss: 5.160\n",
      "--(Epoch, iter): [2,  3150] loss: 5.040\n",
      "--(Epoch, iter): [2,  3200] loss: 4.997\n",
      "--(Epoch, iter): [2,  3250] loss: 4.979\n",
      "--(Epoch, iter): [2,  3300] loss: 5.237\n",
      "--(Epoch, iter): [2,  3350] loss: 4.983\n",
      "--(Epoch, iter): [2,  3400] loss: 4.935\n",
      "--(Epoch, iter): [2,  3450] loss: 5.302\n",
      "--(Epoch, iter): [2,  3500] loss: 4.878\n",
      "--(Epoch, iter): [2,  3550] loss: 4.798\n",
      "--(Epoch, iter): [2,  3600] loss: 4.982\n",
      "--(Epoch, iter): [2,  3650] loss: 4.780\n",
      "--(Epoch, iter): [2,  3700] loss: 4.730\n",
      "--(Epoch, iter): [2,  3750] loss: 4.777\n",
      "Epoch:  1 --- Loss:  tensor(7.5687) ---F1:  0.01337869978858351\n",
      "--(Epoch, iter): [3,    50] loss: 5.715\n",
      "--(Epoch, iter): [3,   100] loss: 5.354\n",
      "--(Epoch, iter): [3,   150] loss: 5.275\n",
      "--(Epoch, iter): [3,   200] loss: 5.117\n",
      "--(Epoch, iter): [3,   250] loss: 4.962\n",
      "--(Epoch, iter): [3,   300] loss: 4.857\n",
      "--(Epoch, iter): [3,   350] loss: 5.001\n",
      "--(Epoch, iter): [3,   400] loss: 5.989\n",
      "--(Epoch, iter): [3,   450] loss: 5.844\n",
      "--(Epoch, iter): [3,   500] loss: 5.697\n",
      "--(Epoch, iter): [3,   550] loss: 5.666\n",
      "--(Epoch, iter): [3,   600] loss: 5.612\n",
      "--(Epoch, iter): [3,   650] loss: 5.638\n",
      "--(Epoch, iter): [3,   700] loss: 5.525\n",
      "--(Epoch, iter): [3,   750] loss: 5.596\n",
      "--(Epoch, iter): [3,   800] loss: 5.501\n",
      "--(Epoch, iter): [3,   850] loss: 5.514\n",
      "--(Epoch, iter): [3,   900] loss: 5.489\n",
      "--(Epoch, iter): [3,   950] loss: 5.462\n",
      "--(Epoch, iter): [3,  1000] loss: 5.401\n",
      "--(Epoch, iter): [3,  1050] loss: 5.294\n",
      "--(Epoch, iter): [3,  1100] loss: 5.172\n",
      "--(Epoch, iter): [3,  1150] loss: 5.142\n",
      "--(Epoch, iter): [3,  1200] loss: 5.199\n",
      "--(Epoch, iter): [3,  1250] loss: 5.148\n",
      "--(Epoch, iter): [3,  1300] loss: 5.106\n",
      "--(Epoch, iter): [3,  1350] loss: 5.082\n",
      "--(Epoch, iter): [3,  1400] loss: 5.041\n",
      "--(Epoch, iter): [3,  1450] loss: 5.056\n",
      "--(Epoch, iter): [3,  1500] loss: 5.132\n",
      "--(Epoch, iter): [3,  1550] loss: 4.980\n",
      "--(Epoch, iter): [3,  1600] loss: 5.674\n",
      "--(Epoch, iter): [3,  1650] loss: 5.300\n",
      "--(Epoch, iter): [3,  1700] loss: 4.994\n",
      "--(Epoch, iter): [3,  1750] loss: 5.827\n",
      "--(Epoch, iter): [3,  1800] loss: 5.328\n",
      "--(Epoch, iter): [3,  1850] loss: 5.009\n",
      "--(Epoch, iter): [3,  1900] loss: 5.173\n",
      "--(Epoch, iter): [3,  1950] loss: 5.176\n",
      "--(Epoch, iter): [3,  2000] loss: 4.999\n",
      "--(Epoch, iter): [3,  2050] loss: 5.171\n",
      "--(Epoch, iter): [3,  2100] loss: 5.315\n",
      "--(Epoch, iter): [3,  2150] loss: 5.062\n",
      "--(Epoch, iter): [3,  2200] loss: 6.596\n",
      "--(Epoch, iter): [3,  2250] loss: 6.465\n",
      "--(Epoch, iter): [3,  2300] loss: 6.268\n",
      "--(Epoch, iter): [3,  2350] loss: 6.200\n",
      "--(Epoch, iter): [3,  2400] loss: 6.144\n",
      "--(Epoch, iter): [3,  2450] loss: 6.099\n",
      "--(Epoch, iter): [3,  2500] loss: 6.061\n",
      "--(Epoch, iter): [3,  2550] loss: 6.037\n",
      "--(Epoch, iter): [3,  2600] loss: 6.032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--(Epoch, iter): [3,  2650] loss: 6.052\n",
      "--(Epoch, iter): [3,  2700] loss: 6.032\n",
      "--(Epoch, iter): [3,  2750] loss: 6.029\n",
      "--(Epoch, iter): [3,  2800] loss: 6.045\n",
      "--(Epoch, iter): [3,  2850] loss: 5.972\n",
      "--(Epoch, iter): [3,  2900] loss: 5.955\n",
      "--(Epoch, iter): [3,  2950] loss: 5.935\n",
      "--(Epoch, iter): [3,  3000] loss: 5.926\n",
      "--(Epoch, iter): [3,  3050] loss: 5.885\n",
      "--(Epoch, iter): [3,  3100] loss: 5.835\n",
      "--(Epoch, iter): [3,  3150] loss: 5.727\n",
      "--(Epoch, iter): [3,  3200] loss: 5.726\n",
      "--(Epoch, iter): [3,  3250] loss: 5.713\n",
      "--(Epoch, iter): [3,  3300] loss: 5.684\n",
      "--(Epoch, iter): [3,  3350] loss: 5.663\n",
      "--(Epoch, iter): [3,  3400] loss: 5.618\n",
      "--(Epoch, iter): [3,  3450] loss: 5.582\n",
      "--(Epoch, iter): [3,  3500] loss: 5.556\n",
      "--(Epoch, iter): [3,  3550] loss: 5.533\n",
      "--(Epoch, iter): [3,  3600] loss: 5.584\n",
      "--(Epoch, iter): [3,  3650] loss: 5.523\n",
      "--(Epoch, iter): [3,  3700] loss: 5.454\n",
      "--(Epoch, iter): [3,  3750] loss: 5.497\n",
      "Epoch:  2 --- Loss:  tensor(6.2205) ---F1:  0.015641516913319237\n",
      "--(Epoch, iter): [4,    50] loss: 5.468\n",
      "--(Epoch, iter): [4,   100] loss: 5.341\n",
      "--(Epoch, iter): [4,   150] loss: 5.314\n",
      "--(Epoch, iter): [4,   200] loss: 5.214\n",
      "--(Epoch, iter): [4,   250] loss: 5.215\n",
      "--(Epoch, iter): [4,   300] loss: 5.202\n",
      "--(Epoch, iter): [4,   350] loss: 5.114\n",
      "--(Epoch, iter): [4,   400] loss: 5.063\n",
      "--(Epoch, iter): [4,   450] loss: 5.001\n",
      "--(Epoch, iter): [4,   500] loss: 4.965\n",
      "--(Epoch, iter): [4,   550] loss: 4.951\n",
      "--(Epoch, iter): [4,   600] loss: 4.996\n",
      "--(Epoch, iter): [4,   650] loss: 5.500\n",
      "--(Epoch, iter): [4,   700] loss: 4.974\n",
      "--(Epoch, iter): [4,   750] loss: 4.956\n",
      "--(Epoch, iter): [4,   800] loss: 4.859\n",
      "--(Epoch, iter): [4,   850] loss: 5.008\n",
      "--(Epoch, iter): [4,   900] loss: 4.903\n",
      "--(Epoch, iter): [4,   950] loss: 5.510\n",
      "--(Epoch, iter): [4,  1000] loss: 5.706\n",
      "--(Epoch, iter): [4,  1050] loss: 5.582\n",
      "--(Epoch, iter): [4,  1100] loss: 5.493\n",
      "--(Epoch, iter): [4,  1150] loss: 5.470\n",
      "--(Epoch, iter): [4,  1200] loss: 5.547\n",
      "--(Epoch, iter): [4,  1250] loss: 5.408\n",
      "--(Epoch, iter): [4,  1300] loss: 5.419\n",
      "--(Epoch, iter): [4,  1350] loss: 5.367\n",
      "--(Epoch, iter): [4,  1400] loss: 5.354\n",
      "--(Epoch, iter): [4,  1450] loss: 5.347\n",
      "--(Epoch, iter): [4,  1500] loss: 5.281\n",
      "--(Epoch, iter): [4,  1550] loss: 5.239\n",
      "--(Epoch, iter): [4,  1600] loss: 5.154\n",
      "--(Epoch, iter): [4,  1650] loss: 4.941\n",
      "--(Epoch, iter): [4,  1700] loss: 4.762\n",
      "--(Epoch, iter): [4,  1750] loss: 4.809\n",
      "--(Epoch, iter): [4,  1800] loss: 4.762\n",
      "--(Epoch, iter): [4,  1850] loss: 4.804\n",
      "--(Epoch, iter): [4,  1900] loss: 4.792\n",
      "--(Epoch, iter): [4,  1950] loss: 4.705\n",
      "--(Epoch, iter): [4,  2000] loss: 4.923\n",
      "--(Epoch, iter): [4,  2050] loss: 5.291\n",
      "--(Epoch, iter): [4,  2100] loss: 4.884\n",
      "--(Epoch, iter): [4,  2150] loss: 4.740\n",
      "--(Epoch, iter): [4,  2200] loss: 4.698\n",
      "--(Epoch, iter): [4,  2250] loss: 4.853\n",
      "--(Epoch, iter): [4,  2300] loss: 4.743\n",
      "--(Epoch, iter): [4,  2350] loss: 4.672\n",
      "--(Epoch, iter): [4,  2400] loss: 4.743\n",
      "--(Epoch, iter): [4,  2450] loss: 4.669\n",
      "--(Epoch, iter): [4,  2500] loss: 6.174\n",
      "--(Epoch, iter): [4,  2550] loss: 5.999\n",
      "--(Epoch, iter): [4,  2600] loss: 5.792\n",
      "--(Epoch, iter): [4,  2650] loss: 5.702\n",
      "--(Epoch, iter): [4,  2700] loss: 5.621\n",
      "--(Epoch, iter): [4,  2750] loss: 5.658\n",
      "--(Epoch, iter): [4,  2800] loss: 5.615\n",
      "--(Epoch, iter): [4,  2850] loss: 5.535\n",
      "--(Epoch, iter): [4,  2900] loss: 5.494\n",
      "--(Epoch, iter): [4,  2950] loss: 5.440\n",
      "--(Epoch, iter): [4,  3000] loss: 5.419\n",
      "--(Epoch, iter): [4,  3050] loss: 5.410\n",
      "--(Epoch, iter): [4,  3100] loss: 5.347\n",
      "--(Epoch, iter): [4,  3150] loss: 5.221\n",
      "--(Epoch, iter): [4,  3200] loss: 5.104\n",
      "--(Epoch, iter): [4,  3250] loss: 5.029\n",
      "--(Epoch, iter): [4,  3300] loss: 4.958\n",
      "--(Epoch, iter): [4,  3350] loss: 4.938\n",
      "--(Epoch, iter): [4,  3400] loss: 4.877\n",
      "--(Epoch, iter): [4,  3450] loss: 4.887\n",
      "--(Epoch, iter): [4,  3500] loss: 5.236\n",
      "--(Epoch, iter): [4,  3550] loss: 4.789\n",
      "--(Epoch, iter): [4,  3600] loss: 5.083\n",
      "--(Epoch, iter): [4,  3650] loss: 4.850\n",
      "--(Epoch, iter): [4,  3700] loss: 4.727\n",
      "--(Epoch, iter): [4,  3750] loss: 5.054\n",
      "Epoch:  3 --- Loss:  tensor(6.7760) ---F1:  0.015096458773784354\n",
      "--(Epoch, iter): [5,    50] loss: 5.055\n",
      "--(Epoch, iter): [5,   100] loss: 4.853\n",
      "--(Epoch, iter): [5,   150] loss: 5.954\n",
      "--(Epoch, iter): [5,   200] loss: 6.230\n",
      "--(Epoch, iter): [5,   250] loss: 6.048\n",
      "--(Epoch, iter): [5,   300] loss: 5.951\n",
      "--(Epoch, iter): [5,   350] loss: 5.818\n",
      "--(Epoch, iter): [5,   400] loss: 5.718\n",
      "--(Epoch, iter): [5,   450] loss: 5.665\n",
      "--(Epoch, iter): [5,   500] loss: 5.581\n",
      "--(Epoch, iter): [5,   550] loss: 5.561\n",
      "--(Epoch, iter): [5,   600] loss: 5.520\n",
      "--(Epoch, iter): [5,   650] loss: 5.533\n",
      "--(Epoch, iter): [5,   700] loss: 5.438\n",
      "--(Epoch, iter): [5,   750] loss: 5.524\n",
      "--(Epoch, iter): [5,   800] loss: 5.425\n",
      "--(Epoch, iter): [5,   850] loss: 5.468\n",
      "--(Epoch, iter): [5,   900] loss: 5.450\n",
      "--(Epoch, iter): [5,   950] loss: 5.408\n",
      "--(Epoch, iter): [5,  1000] loss: 5.397\n",
      "--(Epoch, iter): [5,  1050] loss: 5.367\n",
      "--(Epoch, iter): [5,  1100] loss: 5.286\n",
      "--(Epoch, iter): [5,  1150] loss: 5.268\n",
      "--(Epoch, iter): [5,  1200] loss: 5.351\n",
      "--(Epoch, iter): [5,  1250] loss: 5.190\n",
      "--(Epoch, iter): [5,  1300] loss: 5.192\n",
      "--(Epoch, iter): [5,  1350] loss: 5.141\n",
      "--(Epoch, iter): [5,  1400] loss: 5.041\n",
      "--(Epoch, iter): [5,  1450] loss: 4.908\n",
      "--(Epoch, iter): [5,  1500] loss: 4.868\n",
      "--(Epoch, iter): [5,  1550] loss: 4.911\n",
      "--(Epoch, iter): [5,  1600] loss: 4.791\n",
      "--(Epoch, iter): [5,  1650] loss: 4.863\n",
      "--(Epoch, iter): [5,  1700] loss: 5.096\n",
      "--(Epoch, iter): [5,  1750] loss: 4.946\n",
      "--(Epoch, iter): [5,  1800] loss: 4.836\n",
      "--(Epoch, iter): [5,  1850] loss: 4.743\n",
      "--(Epoch, iter): [5,  1900] loss: 4.738\n",
      "--(Epoch, iter): [5,  1950] loss: 4.715\n",
      "--(Epoch, iter): [5,  2000] loss: 4.786\n",
      "--(Epoch, iter): [5,  2050] loss: 5.341\n",
      "--(Epoch, iter): [5,  2100] loss: 4.896\n",
      "--(Epoch, iter): [5,  2150] loss: 4.625\n",
      "--(Epoch, iter): [5,  2200] loss: 4.612\n",
      "--(Epoch, iter): [5,  2250] loss: 4.821\n",
      "--(Epoch, iter): [5,  2300] loss: 4.635\n",
      "--(Epoch, iter): [5,  2350] loss: 4.595\n",
      "--(Epoch, iter): [5,  2400] loss: 4.940\n",
      "--(Epoch, iter): [5,  2450] loss: 4.601\n",
      "--(Epoch, iter): [5,  2500] loss: 5.763\n",
      "--(Epoch, iter): [5,  2550] loss: 6.055\n",
      "--(Epoch, iter): [5,  2600] loss: 5.980\n",
      "--(Epoch, iter): [5,  2650] loss: 5.889\n",
      "--(Epoch, iter): [5,  2700] loss: 5.663\n",
      "--(Epoch, iter): [5,  2750] loss: 5.476\n",
      "--(Epoch, iter): [5,  2800] loss: 5.284\n",
      "--(Epoch, iter): [5,  2850] loss: 4.988\n",
      "--(Epoch, iter): [5,  2900] loss: 4.839\n",
      "--(Epoch, iter): [5,  2950] loss: 4.835\n",
      "--(Epoch, iter): [5,  3000] loss: 4.853\n",
      "--(Epoch, iter): [5,  3050] loss: 4.838\n",
      "--(Epoch, iter): [5,  3100] loss: 5.675\n",
      "--(Epoch, iter): [5,  3150] loss: 5.380\n",
      "--(Epoch, iter): [5,  3200] loss: 5.273\n",
      "--(Epoch, iter): [5,  3250] loss: 5.244\n",
      "--(Epoch, iter): [5,  3300] loss: 5.108\n",
      "--(Epoch, iter): [5,  3350] loss: 4.990\n",
      "--(Epoch, iter): [5,  3400] loss: 4.855\n",
      "--(Epoch, iter): [5,  3450] loss: 4.745\n",
      "--(Epoch, iter): [5,  3500] loss: 4.738\n",
      "--(Epoch, iter): [5,  3550] loss: 4.676\n",
      "--(Epoch, iter): [5,  3600] loss: 5.038\n",
      "--(Epoch, iter): [5,  3650] loss: 4.653\n",
      "--(Epoch, iter): [5,  3700] loss: 4.551\n",
      "--(Epoch, iter): [5,  3750] loss: 5.457\n",
      "Epoch:  4 --- Loss:  tensor(7.9747) ---F1:  0.012205998942917547\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "loss_list = []\n",
    "f1_list = []\n",
    "iteration_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        train, labels = batch\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        hidden = model.initHidden(train.size(0))\n",
    "        \n",
    "        \n",
    "        outputs, _ = model(train, hidden)\n",
    "        \n",
    "        loss = loss_func(outputs, labels)        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print('--(Epoch, iter): [%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    f1 = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            test, labels = batch\n",
    "            hidden = model.initHidden(test.size(0))\n",
    "            pred, _  = model(test, hidden)\n",
    "            test_loss += loss_func(pred, labels)\n",
    "            \n",
    "            _, pred = torch.max(pred.data, 1)\n",
    "#             print(pred.shape)\n",
    "#             print(labels.shape)\n",
    "            \n",
    "            f1 += f1_score(pred, labels, average = 'micro')\n",
    "            \n",
    "    print(\"Epoch: \", epoch, \"--- Loss: \", test_loss / len(test_loader), '---F1: ', (f1/len(test_loader)))\n",
    "        \n",
    "#         if count %50 == 0:\n",
    "            \n",
    "#             correct = 0\n",
    "#             total = 0\n",
    "#             predicted=[]\n",
    "#             for i, batch in enumerate(test_loader):\n",
    "#                 test, labels = batch\n",
    "#                 test = test.view(batch_size, 1, max_len, vocab_size)\n",
    "                 \n",
    "#                 outputs = model(test)\n",
    "                \n",
    "#                 predicted.append(torch.max(outputs.data, 1)[1])\n",
    "                \n",
    "#             f1 = f1_score(predicted, labelTest)\n",
    "            \n",
    "#             loss_list.append(loss.data)\n",
    "#             iteration_list.append(count)\n",
    "#             if count% 100 == 0:\n",
    "#                 print('Iteration: {}, Loss: {}, F1: {}%'.format(count, loss.data, f1))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"F1: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization F1 \n",
    "plt.plot(iteration_list,f1_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.title(\"BiGRU: F1 vs Number of iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['len'] = x['tweets'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breaking federal judge dismisses president tru...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joe biden grapples attacks president trump ris...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>read letter former national security officials...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt newday jaw floor says sen chriscoons sen ro...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pete buttigieg proposes seizing patents enforc...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets    labels  len\n",
       "0  breaking federal judge dismisses president tru...  Politics   84\n",
       "1  joe biden grapples attacks president trump ris...  Politics   63\n",
       "2  read letter former national security officials...  Politics   89\n",
       "3  rt newday jaw floor says sen chriscoons sen ro...  Politics   95\n",
       "4  pete buttigieg proposes seizing patents enforc...  Politics  113"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = x[x['len'] == x['len'].max()]['tweets'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test= map(torch.tensor, (x_train, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2de196e5636f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = TensorDataset(x_train, y_train)\n",
    "test_loader = TensorDataset(x_test, y_test)\n",
    "train_loader = DataLoader(train_loader, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_loader, batch_size = batch_size * 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
